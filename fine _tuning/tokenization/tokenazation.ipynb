{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sentencepiece as spm\n",
    "#spm.SentencePieceTrainer.train('--input=token.txt --model_prefix=m --vocab_size=2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=Scalable_Datawarehouse_Amharic_Data_Ingestion_For_LLM_RAG/data/clean/cleaned_data.csv --model_prefix=m --vocab_size=2000\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: Scalable_Datawarehouse_Amharic_Data_Ingestion_For_LLM_RAG/data/clean/cleaned_data.csv\n",
      "  input_format: \n",
      "  model_prefix: m\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: Scalable_Datawarehouse_Amharic_Data_Ingestion_For_LLM_RAG/data/clean/cleaned_data.csv\n",
      "trainer_interface.cc(380) LOG(WARNING) Found too long line (5775 > 4192).\n",
      "trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 253833 sentences\n",
      "trainer_interface.cc(416) LOG(INFO) Skipped 1 too long sentences.\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=13742438\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=475\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 246166 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=6779173\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 294001 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 246166\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 249066\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 249066 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=141778 obj=13.9876 num_tokens=636830 num_tokens/piece=4.49174\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=122932 obj=12.1174 num_tokens=639224 num_tokens/piece=5.19982\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=92167 obj=12.1498 num_tokens=664632 num_tokens/piece=7.21117\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=92085 obj=12.1085 num_tokens=665079 num_tokens/piece=7.22245\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=69058 obj=12.2168 num_tokens=699152 num_tokens/piece=10.1241\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=69055 obj=12.1823 num_tokens=699189 num_tokens/piece=10.1251\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=51790 obj=12.3518 num_tokens=736562 num_tokens/piece=14.2221\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=51788 obj=12.3093 num_tokens=736566 num_tokens/piece=14.2227\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=38840 obj=12.5317 num_tokens=775322 num_tokens/piece=19.9619\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=38840 obj=12.4792 num_tokens=775314 num_tokens/piece=19.9617\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=29129 obj=12.7862 num_tokens=817765 num_tokens/piece=28.0739\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=29129 obj=12.7222 num_tokens=817792 num_tokens/piece=28.0748\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=21846 obj=13.1087 num_tokens=865718 num_tokens/piece=39.6282\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=21846 obj=13.0308 num_tokens=865745 num_tokens/piece=39.6295\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=16384 obj=13.4917 num_tokens=915961 num_tokens/piece=55.9058\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=16384 obj=13.4028 num_tokens=915994 num_tokens/piece=55.9078\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12288 obj=13.8932 num_tokens=996546 num_tokens/piece=81.0991\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12288 obj=13.7942 num_tokens=996542 num_tokens/piece=81.0988\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9216 obj=14.3973 num_tokens=1066211 num_tokens/piece=115.691\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9216 obj=14.2939 num_tokens=1066244 num_tokens/piece=115.695\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=6912 obj=14.8747 num_tokens=1130043 num_tokens/piece=163.49\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=6912 obj=14.7685 num_tokens=1130067 num_tokens/piece=163.493\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5184 obj=15.4172 num_tokens=1175124 num_tokens/piece=226.683\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5184 obj=15.2702 num_tokens=1175675 num_tokens/piece=226.789\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3888 obj=15.976 num_tokens=1223814 num_tokens/piece=314.767\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3888 obj=15.8416 num_tokens=1223864 num_tokens/piece=314.78\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2916 obj=16.6058 num_tokens=1274945 num_tokens/piece=437.224\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2916 obj=16.459 num_tokens=1274953 num_tokens/piece=437.227\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2200 obj=17.3643 num_tokens=1330727 num_tokens/piece=604.876\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2200 obj=17.1921 num_tokens=1330725 num_tokens/piece=604.875\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: m.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: m.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train('--input=Scalable_Datawarehouse_Amharic_Data_Ingestion_For_LLM_RAG/data/clean/cleaned_data.csv --model_prefix=m --vocab_size=2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁በ', 'አዳማ', '▁ከተማ', '▁በ', 'ዶ', 'ክ', 'ተር', '▁', 'ዳ', 'ግ', 'ም', '▁አ', 'ሰ', 'ፋ', '▁አማካኝነት', '▁በ', '100', '▁ሚሊየን', '▁ብር', '▁የተ', 'ገነባ', 'ው', '▁', 'ሙ', 'ሴ', '▁', 'ዘመ', 'ና', 'ዊ', '▁ሆስፒታል', '▁የጤና', '▁ሚ', 'ኒ', 'ስት', 'ሯ', '▁ዶክተር', '▁', 'ሊያ', '▁ታ', 'ደ', 'ሰ', '▁እና', '▁የ', 'ኦሮሚያ', '▁ክልል', '▁ጤና', '▁ቢሮ', '▁ሀላፊ', '▁ዶክተር', '▁', 'መንግስ', 'ቱ', '▁በ', 'ቀ', 'ለን', '▁ጨምሮ', '▁የክልሉ', '▁ከፍተኛ', '▁የስራ', '▁ሀላፊ', 'ዎች', '▁በተ', 'ገኙ', 'በት', '▁ተመ', 'ር', 'ቋ', 'ል', '▁', 'ሆ', 'ስ', 'ፒ', 'ታ', 'ሉ', '▁ለ', 'አካባቢው', '▁ማህበረሰብ', '▁የ', 'ጠቅ', 'ላ', 'ላ', '▁ህክምና', '▁አገልግሎት', '▁እንደሚ', 'ሰጥ', '▁ተገልጿል', '▁', 'O', 'B', 'N']\n",
      "[399, 946, 94, 3, 658, 3, 77, 3, 554, 387]\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode_as_pieces('በአዳማ ከተማ በዶክተር ዳግም አሰፋ አማካኝነት በ100 ሚሊየን ብር የተገነባው ሙሴ ዘመናዊ ሆስፒታል የጤና ሚኒስትሯ ዶክተር ሊያ ታደሰ እና የኦሮሚያ ክልል ጤና ቢሮ ሀላፊ ዶክተር መንግስቱ በቀለን ጨምሮ የክልሉ ከፍተኛ የስራ ሀላፊዎች በተገኙበት ተመርቋል ሆስፒታሉ ለአካባቢው ማህበረሰብ የጠቅላላ ህክምና አገልግሎት እንደሚሰጥ ተገልጿል OBN'))\n",
    "print(sp.encode_as_ids('This is a test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
